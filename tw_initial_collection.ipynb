{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Data Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Reddit API scraper\n",
    "# Taken from Ada PRAW lesson\n",
    "\n",
    "reddit_tw = praw.Reddit(client_id = 'oyQm0DwF4Do0yQ', # Personal script key\n",
    "                     client_secret = 'jYqM7fjnvbI55QRe1Xl09hb62-k', # Personal secret key\n",
    "                     user_agent = 'TAW', # Personal application name\n",
    "                     username = 'tawhalen', # Personal Reddit user name\n",
    "                     password = '9bry2' # Personal Reddit password - Please don't post weird things\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of target subreddits\n",
    "target_subreddits = ['nfl','patriots']\n",
    "\n",
    "# Choose target posts from list of: new, hot, top\n",
    "target_posts = 'new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subreddit_data(subs_list, reddit_scrape, method = 'new'):\n",
    "    \"\"\"Returns dictionary of posts pulled from given list of subreddits\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    subs_list: list\n",
    "        List of target subreddits for scrape. Must be valid subreddits.\n",
    "    reddit_scrape: praw.Reddit()\n",
    "        Instantiated PRAW Reddit scrape with desired parameters\n",
    "    method: str\n",
    "        Method to be called upon the PRAW. This determines which type of posts to scrape.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dictionary\n",
    "        A dictionary including the subreddit, post title, post score, user id, url, comments number, created time (utc epoch seconds), and post body.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Create dictionary of empty lists in format of reddit posts\n",
    "    # Add subreddit to allow differentiation\n",
    "    dict_subreddits = { \"subreddit\":[],\n",
    "                        \"title\":[],\n",
    "                        \"score\":[],\n",
    "                        \"id\":[],\n",
    "                        \"url\":[], \n",
    "                        \"comms_num\": [],\n",
    "                        \"created_utc\": [],\n",
    "                        \"body\":[]\n",
    "                      }\n",
    "\n",
    "    # Loop through chosen subreddits, pull data through PRAW, and add results to dictionary\n",
    "    for sub in subs_list:\n",
    "\n",
    "        # Create subreddit pull of 1000 records from chosen category\n",
    "        # Dynamic method call take from:\n",
    "        # https://stackoverflow.com/questions/17726180/how-to-dynamically-call-a-method-in-python\n",
    "        subreddit_pull = getattr(reddit_scrape.subreddit(sub),method)(limit = 1000)\n",
    "\n",
    "        # Create a record counter to track number of rows\n",
    "        record_count = 0\n",
    "\n",
    "        # Loop through each record and add data to the dictionary\n",
    "        for item in subreddit_pull:\n",
    "            dict_subreddits[\"subreddit\"].append(sub)\n",
    "            dict_subreddits[\"title\"].append(item.title)\n",
    "            dict_subreddits[\"score\"].append(item.score)\n",
    "            dict_subreddits[\"id\"].append(item.id)\n",
    "            dict_subreddits[\"url\"].append(item.url)\n",
    "            dict_subreddits[\"comms_num\"].append(item.num_comments)\n",
    "            dict_subreddits[\"created_utc\"].append(item.created_utc)\n",
    "            dict_subreddits[\"body\"].append(item.selftext)\n",
    "            record_count += 1\n",
    "\n",
    "        # Check that at least 900 records have been pulled for each subreddit\n",
    "        if record_count < 900:\n",
    "            raise Exception(f'Insufficient data: the {sub} subreddit returned only {record_count} records.')\n",
    "      \n",
    "    # Return the completed data pull\n",
    "    return dict_subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert scrape dictionaries into a dataframe\n",
    "df_subreddits = pd.DataFrame(get_subreddit_data(target_subreddits, reddit_tw, target_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Write Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write raw subreddits data as .csv file\n",
    "df_subreddits.to_csv('./data/subreddits_raw.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
